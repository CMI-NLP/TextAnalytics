\begin{frame}{Introduction}
\begin{itemize}
\item LLMs have transformed artificial intelligence, extending beyond traditional NLP.
Formal logic systems but struggled with real-world complexity.
LLMs learn knowledge and reasoning from data.
Fundamental change: Programmed logic $\rightarrow$ learned reasoning
LLMs' ability to acquire knowledge opens up a new avenue in reasoning.
May lead to verifiability in many tasks $\rightarrow$ legal analysis, scientific discovery,$\cdots$
Traditional Reasoning in AI involves applying structured rules to derive conclusions.
LLM-based reasoning  integrates natural language understanding enables multi-step deduction and abstraction.
Can this lead to generalization of inferences?
Algorithmic reasoning may lead to
Multi-step thought processes which may enhance the clarity and trustworthiness of LLM outcomes.

\end{itemize}
\end{frame}